# AlertManager Runbook

This runbook provides operational guidance for responding to alerts generated by the CryptoFunk trading system.

## Table of Contents

- [Alert Severity Levels](#alert-severity-levels)
- [Alert Categories](#alert-categories)
- [Alert Response Procedures](#alert-response-procedures)
- [Circuit Breaker Alerts](#circuit-breaker-alerts)
- [Trading Alerts](#trading-alerts)
- [Agent Health Alerts](#agent-health-alerts)
- [System Resource Alerts](#system-resource-alerts)
- [Alert Notification Channels](#alert-notification-channels)
- [Escalation Procedures](#escalation-procedures)

## Alert Severity Levels

### Critical
- **Response Time**: Immediate (within 15 minutes)
- **Impact**: Trading system is down or at risk of significant financial loss
- **Actions**:
  - Check alert details in Slack #cryptofunk-critical
  - Access AlertManager UI at http://alertmanager-service:9093
  - Follow specific alert procedure below
  - Escalate to on-call engineer if not resolved within 30 minutes

### Warning
- **Response Time**: Within 1 hour
- **Impact**: System degradation or potential future issues
- **Actions**:
  - Review alert in Slack #cryptofunk-alerts
  - Investigate root cause during business hours
  - Monitor for escalation to critical

### Info
- **Response Time**: Best effort
- **Impact**: Informational, no immediate action required
- **Actions**:
  - Review during regular maintenance windows
  - Use for trend analysis and capacity planning

## Alert Categories

### 1. Circuit Breaker Alerts
### 2. Trading Alerts
### 3. Agent Health Alerts
### 4. System Resource Alerts
### 5. Infrastructure Alerts

## Alert Response Procedures

### CircuitBreakerOpen

**Severity**: Warning (can escalate to Critical)

**Description**: A circuit breaker has opened for a critical service (exchange, LLM, or database).

**Impact**:
- Exchange circuit breaker: Cannot place new orders
- LLM circuit breaker: Agent decision-making degraded
- Database circuit breaker: Cannot persist data

**Response Steps**:

1. **Identify the affected service**:
   ```bash
   # Check AlertManager
   curl http://alertmanager-service:9093/api/v2/alerts | jq '.[] | select(.labels.alertname == "CircuitBreakerOpen")'

   # Check Prometheus metrics
   curl http://prometheus-service:9090/api/v1/query?query=circuit_breaker_state | jq
   ```

2. **Check service health**:
   ```bash
   # For exchange circuit breaker
   kubectl logs -n cryptofunk deployment/order-executor-server --tail=100

   # For LLM circuit breaker
   kubectl logs -n cryptofunk deployment/bifrost --tail=100

   # For database circuit breaker
   kubectl logs -n cryptofunk deployment/postgres --tail=100
   kubectl exec -it -n cryptofunk deployment/postgres -- psql -U postgres -c "SELECT 1;"
   ```

3. **Check failure rate**:
   ```bash
   # View recent failures
   circuit_breaker_failures_total{service="exchange"}
   circuit_breaker_requests_total{service="exchange",result="failure"}
   ```

4. **Remediation**:
   - **Exchange**: Check API keys, rate limits, network connectivity
   - **LLM**: Check Bifrost logs, verify API keys, check provider status
   - **Database**: Check connection pool, disk space, PostgreSQL logs

5. **Recovery**:
   - Circuit breakers automatically transition to half-open state after timeout
   - Monitor metrics for successful requests
   - If failures persist, investigate root cause before forcing reset

6. **Prevention**:
   - Review error logs for patterns
   - Adjust circuit breaker thresholds if needed (internal/risk/circuit_breaker.go)
   - Implement additional retry logic or fallback mechanisms

---

### HighErrorRate

**Severity**: Critical

**Description**: Error rate exceeds threshold (>5% for 5 minutes).

**Impact**: System functionality degraded, potential financial loss.

**Response Steps**:

1. **Check error logs**:
   ```bash
   kubectl logs -n cryptofunk deployment/orchestrator --tail=200 | grep -i error
   kubectl logs -n cryptofunk deployment/api --tail=200 | grep -i error
   ```

2. **Identify error patterns**:
   ```bash
   # Check Prometheus for error metrics
   rate(http_requests_total{status=~"5.."}[5m])
   rate(mcp_tool_errors_total[5m])
   ```

3. **Check dependencies**:
   - Database connectivity
   - Redis availability
   - NATS messaging
   - External APIs (CoinGecko, exchange)

4. **Remediation**:
   - If database: Check connections, run migrations
   - If external API: Check rate limits, verify credentials
   - If internal service: Check resource limits, restart if needed

5. **Communication**:
   - Update #cryptofunk-critical with status
   - Notify stakeholders if trading is affected

---

### TradingSessionFailure

**Severity**: Critical

**Description**: Trading session failed to start or crashed.

**Impact**: No trading activity, potential missed opportunities.

**Response Steps**:

1. **Check orchestrator status**:
   ```bash
   kubectl logs -n cryptofunk deployment/orchestrator --tail=100
   kubectl get pods -n cryptofunk -l app.kubernetes.io/name=orchestrator
   ```

2. **Verify agent health**:
   ```bash
   kubectl get pods -n cryptofunk -l app.kubernetes.io/component=trading-agent

   # Check agent_status table
   kubectl exec -it -n cryptofunk deployment/postgres -- \
     psql -U postgres -d cryptofunk -c \
     "SELECT agent_name, status, last_heartbeat FROM agent_status ORDER BY last_heartbeat DESC;"
   ```

3. **Check MCP server connectivity**:
   ```bash
   # Test market data server
   kubectl exec -it -n cryptofunk deployment/orchestrator -- \
     curl http://market-data-server:9201/health

   # Test other MCP servers
   for server in technical-indicators risk-analyzer order-executor; do
     echo "Checking $server..."
     kubectl exec -it -n cryptofunk deployment/orchestrator -- \
       curl http://${server}-server:920X/health
   done
   ```

4. **Restart trading session**:
   ```bash
   # Gracefully restart orchestrator
   kubectl rollout restart deployment/orchestrator -n cryptofunk

   # Monitor startup
   kubectl logs -f -n cryptofunk deployment/orchestrator
   ```

5. **Verify recovery**:
   - Check trading_sessions table for new session
   - Verify agent signals are being generated
   - Monitor order placement

---

### PositionLimitExceeded

**Severity**: Warning (escalates to Critical if repeated)

**Description**: Position size or exposure exceeded configured limits.

**Impact**: Risk management violation, potential for excessive loss.

**Response Steps**:

1. **Check current positions**:
   ```bash
   kubectl exec -it -n cryptofunk deployment/postgres -- \
     psql -U postgres -d cryptofunk -c \
     "SELECT symbol, side, quantity, entry_price, current_price, unrealized_pnl
      FROM positions WHERE status = 'OPEN' ORDER BY unrealized_pnl;"
   ```

2. **Review risk limits**:
   ```bash
   # Check risk analyzer configuration
   kubectl logs -n cryptofunk deployment/risk-analyzer-server | grep -i "limit"
   ```

3. **Manual intervention**:
   - If position is truly too large, consider reducing exposure
   - Review strategy agent that opened the position
   - Update risk limits if appropriate

4. **Investigation**:
   - Check why risk agent allowed the position
   - Review agent_signals table for decision reasoning
   - Verify risk calculation logic

5. **Prevention**:
   - Adjust position sizing parameters
   - Implement stricter pre-trade risk checks
   - Review and update risk limits in configs/config.yaml

---

### MaxDrawdownExceeded

**Severity**: Critical

**Description**: Portfolio drawdown exceeded maximum threshold.

**Impact**: Circuit breaker triggered, trading halted.

**Response Steps**:

1. **Verify drawdown**:
   ```bash
   kubectl exec -it -n cryptofunk deployment/postgres -- \
     psql -U postgres -d cryptofunk -c \
     "SELECT session_id, total_pnl, max_drawdown, roi_percentage
      FROM trading_sessions ORDER BY created_at DESC LIMIT 1;"
   ```

2. **Review losing trades**:
   ```bash
   kubectl exec -it -n cryptofunk deployment/postgres -- \
     psql -U postgres -d cryptofunk -c \
     "SELECT symbol, side, quantity, entry_price, exit_price, realized_pnl
      FROM positions WHERE status = 'CLOSED' AND realized_pnl < 0
      ORDER BY realized_pnl LIMIT 20;"
   ```

3. **Assess market conditions**:
   - Check for unusual market volatility
   - Review recent price movements
   - Identify if drawdown is strategy-specific or market-wide

4. **Decision point**:
   - **Continue trading**: If drawdown is temporary and market conditions are normalizing
   - **Pause trading**: If market conditions are adverse or strategy is flawed
   - **Modify strategy**: Adjust parameters if specific strategy is underperforming

5. **Recovery**:
   ```bash
   # If resuming trading, restart orchestrator
   kubectl rollout restart deployment/orchestrator -n cryptofunk

   # Monitor closely for continued losses
   kubectl logs -f -n cryptofunk deployment/risk-agent
   ```

6. **Post-mortem**:
   - Analyze what led to drawdown
   - Review strategy performance metrics
   - Update risk parameters if needed

---

### AgentDown / AgentUnhealthy

**Severity**: Warning

**Description**: Trading agent is not responding or failing health checks.

**Impact**: Reduced decision-making capacity, potential missed trading opportunities.

**Response Steps**:

1. **Identify affected agent**:
   ```bash
   # Check pod status
   kubectl get pods -n cryptofunk -l app.kubernetes.io/component=trading-agent

   # Check agent health in database
   kubectl exec -it -n cryptofunk deployment/postgres -- \
     psql -U postgres -d cryptofunk -c \
     "SELECT agent_name, status, last_heartbeat, error_message
      FROM agent_status WHERE status != 'ACTIVE';"
   ```

2. **Check agent logs**:
   ```bash
   # Replace <agent-name> with specific agent (e.g., technical-agent)
   kubectl logs -n cryptofunk deployment/<agent-name> --tail=100
   ```

3. **Common issues**:
   - **LLM API failure**: Check Bifrost logs and API key validity
   - **MCP server connectivity**: Verify MCP servers are healthy
   - **Database connection**: Check connection pool and database health
   - **Resource limits**: Check if pod is OOM or CPU throttled

4. **Restart agent**:
   ```bash
   kubectl rollout restart deployment/<agent-name> -n cryptofunk
   kubectl logs -f -n cryptofunk deployment/<agent-name>
   ```

5. **Verify recovery**:
   - Check agent_status table shows ACTIVE
   - Verify agent is generating signals
   - Monitor for repeated failures

---

### AgentHighLatency

**Severity**: Warning

**Description**: Agent decision-making taking longer than expected (>5 seconds).

**Impact**: Delayed trading decisions, potential missed opportunities.

**Response Steps**:

1. **Check agent performance metrics**:
   ```bash
   # Query Prometheus
   histogram_quantile(0.95, rate(agent_decision_duration_seconds_bucket[5m]))
   ```

2. **Identify bottleneck**:
   - **LLM latency**: Check Bifrost response times
   - **MCP tool latency**: Check tool call durations
   - **Database queries**: Check slow query log
   - **Resource constraints**: Check CPU/memory usage

3. **Investigate LLM performance**:
   ```bash
   kubectl logs -n cryptofunk deployment/bifrost --tail=100 | grep -i latency
   ```

4. **Database optimization**:
   ```bash
   # Check for slow queries
   kubectl exec -it -n cryptofunk deployment/postgres -- \
     psql -U postgres -d cryptofunk -c \
     "SELECT query, mean_exec_time, calls
      FROM pg_stat_statements
      ORDER BY mean_exec_time DESC LIMIT 10;"
   ```

5. **Remediation**:
   - If LLM: Switch to faster model or increase timeout
   - If database: Add indexes, optimize queries
   - If resource: Increase pod limits

---

### HighMemoryUsage / HighCPUUsage

**Severity**: Warning

**Description**: Pod memory or CPU usage exceeding 80%.

**Impact**: Performance degradation, potential pod eviction or OOM kill.

**Response Steps**:

1. **Identify affected pod**:
   ```bash
   kubectl top pods -n cryptofunk --sort-by=memory
   kubectl top pods -n cryptofunk --sort-by=cpu
   ```

2. **Check resource limits**:
   ```bash
   kubectl describe pod -n cryptofunk <pod-name> | grep -A 10 "Limits:"
   ```

3. **Investigate memory leak**:
   ```bash
   # For Go applications, check heap profile
   kubectl exec -it -n cryptofunk <pod-name> -- \
     curl http://localhost:6060/debug/pprof/heap > heap.prof

   # Analyze with pprof
   go tool pprof heap.prof
   ```

4. **Remediation**:
   - **Short-term**: Increase resource limits
   - **Long-term**: Fix memory leak or optimize code

5. **Increase resources**:
   ```bash
   # Edit deployment to increase limits
   kubectl edit deployment <deployment-name> -n cryptofunk

   # Or use kubectl patch
   kubectl patch deployment <deployment-name> -n cryptofunk -p \
     '{"spec":{"template":{"spec":{"containers":[{"name":"<container>","resources":{"limits":{"memory":"2Gi"}}}]}}}}'
   ```

---

### DiskSpaceWarning

**Severity**: Warning

**Description**: Persistent volume disk usage exceeding 80%.

**Impact**: Database or storage failures if disk fills completely.

**Response Steps**:

1. **Check disk usage**:
   ```bash
   kubectl exec -it -n cryptofunk deployment/postgres -- df -h
   ```

2. **Identify large tables**:
   ```bash
   kubectl exec -it -n cryptofunk deployment/postgres -- \
     psql -U postgres -d cryptofunk -c \
     "SELECT schemaname, tablename,
             pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
      FROM pg_tables
      WHERE schemaname NOT IN ('pg_catalog', 'information_schema')
      ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
      LIMIT 10;"
   ```

3. **Apply TimescaleDB compression**:
   ```bash
   # Compress old data
   kubectl exec -it -n cryptofunk deployment/postgres -- \
     psql -U postgres -d cryptofunk -c \
     "SELECT compress_chunk(i, if_not_compressed => true)
      FROM show_chunks('candlesticks', older_than => INTERVAL '7 days') i;"
   ```

4. **Archive old data**:
   ```bash
   # Export old trading sessions
   kubectl exec -it -n cryptofunk deployment/postgres -- \
     pg_dump -U postgres -d cryptofunk -t trading_sessions \
     --where="created_at < NOW() - INTERVAL '90 days'" > archive.sql

   # Delete archived data
   kubectl exec -it -n cryptofunk deployment/postgres -- \
     psql -U postgres -d cryptofunk -c \
     "DELETE FROM trading_sessions WHERE created_at < NOW() - INTERVAL '90 days';"
   ```

5. **Expand volume**:
   ```bash
   # Increase PVC size (requires storage class with allowVolumeExpansion: true)
   kubectl patch pvc postgres-pvc -n cryptofunk -p \
     '{"spec":{"resources":{"requests":{"storage":"100Gi"}}}}'
   ```

---

## Alert Notification Channels

### Slack Channels

- **#cryptofunk-alerts**: All alerts (info, warning, critical)
- **#cryptofunk-critical**: Critical alerts only (@channel mentions)
- **#cryptofunk-trading**: Trading-specific alerts
- **#cryptofunk-agents**: Agent health alerts
- **#cryptofunk-ops**: System and circuit breaker alerts

### Email

- **team@example.com**: Regular alerts (configured via `ALERT_EMAIL_TO`)
- **oncall@example.com**: Critical alerts (configured via `CRITICAL_ALERT_EMAIL_TO`)

### Configuration

Alert notification settings are configured in:
- **Docker Compose**: `docker-compose.yml` environment variables
- **Kubernetes**: `deployments/k8s/base/secrets.yaml`

Required environment variables:
```bash
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/WEBHOOK/URL
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_FROM=cryptofunk-alerts@example.com
SMTP_USERNAME=your-username
SMTP_PASSWORD=your-password
ALERT_EMAIL_TO=team@example.com
CRITICAL_ALERT_EMAIL_TO=oncall@example.com
```

---

## Escalation Procedures

### Level 1: Team Response (0-30 minutes)
- On-call engineer receives alert
- Follows runbook procedures
- Attempts immediate remediation
- Updates #cryptofunk-critical with status

### Level 2: Senior Engineer Escalation (30-60 minutes)
- If issue not resolved within 30 minutes
- Senior engineer joins incident response
- Reviews remediation attempts
- Coordinates with external dependencies (exchange, LLM provider)

### Level 3: Emergency Escalation (60+ minutes)
- If trading system down for >1 hour
- Escalate to engineering lead and product manager
- Consider emergency maintenance window
- Prepare external communication for stakeholders

### Escalation Contacts

Update with your team's contact information:

- **On-Call Engineer**: [Slack: @oncall] [Phone: +1-XXX-XXX-XXXX]
- **Senior Engineer**: [Slack: @senior-eng] [Phone: +1-XXX-XXX-XXXX]
- **Engineering Lead**: [Slack: @eng-lead] [Phone: +1-XXX-XXX-XXXX]
- **Product Manager**: [Slack: @pm] [Phone: +1-XXX-XXX-XXXX]

---

## Useful Commands Reference

### Check All Alert Status
```bash
curl http://alertmanager-service:9093/api/v2/alerts | jq
```

### Silence an Alert
```bash
# Create silence for 1 hour
amtool silence add alertname=CircuitBreakerOpen --duration=1h \
  --comment="Investigating circuit breaker issue"
```

### View Alert History
```bash
# Query Prometheus for alert history
curl -G http://prometheus-service:9090/api/v1/query \
  --data-urlencode 'query=ALERTS{alertname="CircuitBreakerOpen"}[1h]' | jq
```

### Check Trading System Health
```bash
# Overall system health
kubectl get pods -n cryptofunk

# Database health
kubectl exec -it -n cryptofunk deployment/postgres -- \
  psql -U postgres -c "SELECT 1;"

# Recent trading activity
kubectl exec -it -n cryptofunk deployment/postgres -- \
  psql -U postgres -d cryptofunk -c \
  "SELECT COUNT(*) FROM orders WHERE created_at > NOW() - INTERVAL '1 hour';"
```

---

## Additional Resources

- **Prometheus**: http://prometheus-service:9090
- **AlertManager**: http://alertmanager-service:9093
- **Grafana**: http://grafana-service:3000
- **API Health**: http://api-service:8080/health
- **Orchestrator Health**: http://orchestrator-service:8080/health

For detailed architecture information, see:
- `docs/MCP_INTEGRATION.md`
- `docs/LLM_AGENT_ARCHITECTURE.md`
- `CLAUDE.md`
